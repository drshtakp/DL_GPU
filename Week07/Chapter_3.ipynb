{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Ch3. Convolutional neural networks\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# This chapter covers\n",
        "\n",
        "-   How tensors represent spatial data\n",
        "-   Defining convolutions and their uses\n",
        "-   Building and training a convolutional neural network (CNN)\n",
        "-   Adding pooling to make CNNs more robust\n",
        "-   Augmenting image data to improve accuracy\n",
        "\n",
        "The success of convolutions comes from their ability to learn spatial patterns, which has made them the default method to use for any data resembling an image.\n",
        "\n",
        "-   First, we discuss how images are represented to a neural network.\n",
        "    -   That images are 2D is an important structure or meaning we will encode into the specific way we organize data in our tensors.\n",
        "    -   You should always care about the structure of your data because picking the right architecture to match the structure is the best way to improve the accuracy of your model.\n",
        "-   Next, we remove the mystery of what a convolution is, show how convolutions can detect simple patterns, and explain why they're a good approach for data structured like an image.\n",
        "-   Then, we'll create a convolutional layer, which can act as a replacement for the `nn.Linear` layer we used in the previous chapter.\n",
        "-   Finally, we build some CNNs and discuss a few additional tricks to improve their accuracy.\n",
        "\n",
        "## R-Python Toolkits if Run in RStudio\n",
        "\n",
        "## R-Python Toolkits if Run in RStudio\n",
        "\n",
        "-   `library(reticulate)`\n",
        "-   Gilbreth `use_python(\"/depot/gdsp/apps/MLPy/bin/python3\")`\n",
        "-   Local (example only) `use_python(\"/Users/wen-wen/opt/miniconda3/envs/dl/bin/python3\")`\n",
        "-   `py_config()`\n",
        "-   `repl_python()`\n",
        "\n",
        "## Jupyter Kernel to Use if Run in Jupyter Notebook\n",
        "\n",
        "-   Gilbreth: `MLPy-py3.8.5` or `learning/conda-2020.11-py38-gpu`\n",
        "\n",
        "## 3.1 Spatial structural prior beliefs\n",
        "\n",
        "[Figure 3.1](https://learning.oreilly.com/library/view/inside-deep-learning/9781617298639/OEBPS/Text/03.html#:-:text=Figure%203.1%20Columnar,images%20instead%20of%20audio.) shows some of the cases where you want to use a CNN.\n",
        "\n",
        "[Figure 3.2](https://learning.oreilly.com/library/view/inside-deep-learning/9781617298639/OEBPS/Text/03.html#:-:text=Figure%203.2%20Shuffling,good%20fit%20for%20images.) Images are structured. There is an order to the pixels. If you shuffled the pixels around, you would fundamentally change the meaning of a picture.\n",
        "\n",
        "Suppose we have N images, and each has a height H and a width W. As a starting point, we might consider a matrix of image data to have the shape, `(N,W,H)`, a three-dimensional tensor. Color, in addition, is represented with channels C `(N,C,W,H)`, a four-dimensional tensor. [Convolutions use this approach so that when a convolution looks at pixel location i, j in an image, it can also consider the neighboring pixel locations.](https://learning.oreilly.com/library/view/inside-deep-learning/9781617298639/OEBPS/Text/03.html#:-:text=Convolutions%20use%20this,neighboring%20pixel%20locations.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.292652Z",
          "start_time": "2021-03-22T14:56:50.045676Z"
        },
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "# use os.system  to execute the python script provided by author\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import time\n",
        "\n",
        "import os\n",
        "os.system(f'python idlmam.py')\n",
        "from idlmam import train_simple_network, set_seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.300000Z",
          "start_time": "2021-03-22T14:56:51.294314Z"
        },
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('png', 'pdf')\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic=True\n",
        "set_seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.351972Z",
          "start_time": "2021-03-22T14:56:51.309417Z"
        }
      },
      "source": [
        "import torchvision \n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Now we can load the MNIST dataset using the following code](https://learning.oreilly.com/library/view/inside-deep-learning/9781617298639/OEBPS/Text/03.html#:-:text=Now%20we%20can%20load%20the%20MNIST%20dataset%20using%20the%20following%20code.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.379280Z",
          "start_time": "2021-03-22T14:56:51.354271Z"
        }
      },
      "source": [
        "mnist_data_train = torchvision.datasets.MNIST(\"./data\", train=True, download=True)\n",
        "mnist_data_test = torchvision.datasets.MNIST(\"./data\", train=False, download=True)\n",
        "x_example, y_example = mnist_data_train[0]\n",
        "type(x_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Transform image data to tensor:](https://learning.oreilly.com/library/view/inside-deep-learning/9781617298639/OEBPS/Text/03.html#:-:text=We%20need%20to%20use,transforms%20package%20from%20torchvision.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.408830Z",
          "start_time": "2021-03-22T14:56:51.380844Z"
        }
      },
      "source": [
        "mnist_data_train = torchvision.datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_data_test = torchvision.datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "x_example, y_example = mnist_data_train[0]\n",
        "print(x_example.shape)\n",
        "print(y_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.595917Z",
          "start_time": "2021-03-22T14:56:51.409942Z"
        },
        "max_h": 0.3
      },
      "source": [
        "imshow(x_example[0,:], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.601538Z",
          "start_time": "2021-03-22T14:56:51.597195Z"
        }
      },
      "source": [
        "x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]], dim=0)\n",
        "print(x_as_color.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.764490Z",
          "start_time": "2021-03-22T14:56:51.602584Z"
        },
        "max_h": 0.3
      },
      "source": [
        "imshow(x_as_color.permute(1,2,0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:51.929352Z",
          "start_time": "2021-03-22T14:56:51.765727Z"
        },
        "max_h": 0.3
      },
      "source": [
        "x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]])\n",
        "x_as_color[0,:] = 0 #No Red\n",
        "#Leaving green alone\n",
        "x_as_color[2,:] = 0 #No Blue\n",
        "imshow(x_as_color.permute(1,2,0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:52.092769Z",
          "start_time": "2021-03-22T14:56:51.930590Z"
        },
        "max_h": 0.3
      },
      "source": [
        "#grab 3 images\n",
        "x1, x2, x3 = mnist_data_train[0], mnist_data_train[1], mnist_data_train[2]\n",
        "#drop the labels\n",
        "x1, x2, x3 = x1[0], x2[0], x3[0]\n",
        "x_as_color = torch.stack([x1[0,:], x2[0,:], x3[0,:]], dim=0)\n",
        "imshow(x_as_color.permute(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:52.258941Z",
          "start_time": "2021-03-22T14:56:52.094057Z"
        },
        "max_h": 0.3
      },
      "source": [
        "rand_order = torch.randperm(x_example.shape[1] * x_example.shape[2])\n",
        "x_shuffled = x_example.view(-1)[rand_order].view(x_example.shape)\n",
        "imshow(x_shuffled[0,:], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:52.486229Z",
          "start_time": "2021-03-22T14:56:52.260269Z"
        },
        "max_h": 0.3
      },
      "source": [
        "from scipy.signal import convolve\n",
        "img_indx = 58\n",
        "img = mnist_data_train[img_indx][0][0,:]\n",
        "plt.imshow(img, vmin=0, vmax=1, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:52.653303Z",
          "start_time": "2021-03-22T14:56:52.487509Z"
        },
        "max_h": 0.3
      },
      "source": [
        "blur_filter = np.asarray([[1,1,1],\n",
        "                          [1,1,1],\n",
        "                          [1,1,1]\n",
        "                         ])/9.0\n",
        "\n",
        "blurry_img = convolve(img, blur_filter)\n",
        "plt.imshow(blurry_img, vmin=0, vmax=1, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:52.819553Z",
          "start_time": "2021-03-22T14:56:52.654427Z"
        },
        "max_h": 0.3
      },
      "source": [
        "#We can find edges by focusing on the difference between a pixel, and its neighbors\n",
        "edge_filter = np.asarray([[-1,-1,-1],\n",
        "                          [-1, 8,-1],\n",
        "                          [-1,-1,-1]\n",
        "                         ])\n",
        "\n",
        "\n",
        "edge_img = convolve(img, edge_filter)\n",
        "plt.imshow(edge_img, vmin=0, vmax=1, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:52.986823Z",
          "start_time": "2021-03-22T14:56:52.822341Z"
        },
        "max_h": 0.3
      },
      "source": [
        "#We could look for only horizontal edges\n",
        "h_edge_filter = np.asarray([[-1,-1,-1],\n",
        "                          [0, 0,0],\n",
        "                          [1, 1, 1]\n",
        "                         ])\n",
        "\n",
        "\n",
        "h_edge_img = convolve(img, h_edge_filter)\n",
        "plt.imshow(h_edge_img, vmin=0, vmax=1, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4.4 PyTorch code for first CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:53.024397Z",
          "start_time": "2021-03-22T14:56:52.988368Z"
        }
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "B = 32\n",
        "mnist_train_loader = DataLoader(mnist_data_train, batch_size=B, shuffle=True)\n",
        "mnist_test_loader = DataLoader(mnist_data_test, batch_size=B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T14:56:53.032073Z",
          "start_time": "2021-03-22T14:56:53.025573Z"
        }
      },
      "source": [
        "#How many values are in the input? We use this to help determine the size of subsequent layers\n",
        "D = 28*28 #28 * 28 images \n",
        "#How many channels are in the input?\n",
        "C = 1\n",
        "#How many classes are there?\n",
        "classes = 10\n",
        "#How many filters should we use\n",
        "filters = 16\n",
        "#how large should our filters be?\n",
        "K = 3\n",
        "#for comparison, lets define a linear model of similar complexity\n",
        "model_linear = nn.Sequential(\n",
        "  nn.Flatten(), #(B, C, W, H) -> (B, C*W*H) = (B,D)\n",
        "  nn.Linear(D, 256), \n",
        "  nn.Tanh(),\n",
        "  nn.Linear(256, classes),\n",
        ")\n",
        "\n",
        "#A simple convolutional network:\n",
        "model_cnn = nn.Sequential(\n",
        "  #Conv2d follows the pattern of:\n",
        "  #Conv2d(# of input channels, #filters/output-channels, #filter-size)\n",
        "  nn.Conv2d(C, filters, K, padding=K//2), #$x \\circledast G$\n",
        "  nn.Tanh(),#Activation functions work on any size tensor\n",
        "  nn.Flatten(), #Convert from (B, C, W, H) ->(B, D). This way we can use a Linear layer after\n",
        "  nn.Linear(filters*D, classes),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:02:46.846007Z",
          "start_time": "2021-03-22T14:56:53.033558Z"
        },
        "tags": [
          "remove_output"
        ]
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "cnn_results = train_simple_network(model_cnn, loss_func, mnist_train_loader, test_loader=mnist_test_loader, score_funcs={'Accuracy': accuracy_score}, device=device, epochs=20)\n",
        "fc_results = train_simple_network(model_linear, loss_func, mnist_train_loader, test_loader=mnist_test_loader, score_funcs={'Accuracy': accuracy_score}, device=device, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:02:47.104806Z",
          "start_time": "2021-03-22T15:02:46.847188Z"
        }
      },
      "source": [
        "sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results, label='CNN')\n",
        "sns.lineplot(x='epoch', y='test Accuracy', data=fc_results, label='Fully Conected')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:02:47.425221Z",
          "start_time": "2021-03-22T15:02:47.110382Z"
        },
        "max_h": 0.4
      },
      "source": [
        "img_indx = 0\n",
        "img, correct_class = mnist_data_train[img_indx]\n",
        "img = img[0,:]\n",
        "#move to the lower right, then upper left\n",
        "img_lr = np.roll(np.roll(img, 1, axis=1), 1, axis=0)\n",
        "img_ul = np.roll(np.roll(img, -1, axis=1), -1, axis=0)\n",
        "#plot the images\n",
        "f, axarr = plt.subplots(1,3)\n",
        "axarr[0].imshow(img, cmap='gray')\n",
        "axarr[1].imshow(img_lr, cmap='gray')\n",
        "axarr[2].imshow(img_ul, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:02:47.430933Z",
          "start_time": "2021-03-22T15:02:47.426453Z"
        }
      },
      "source": [
        "#eval mode since we are not training\n",
        "model = model_cnn.cpu().eval()\n",
        "\n",
        "def pred(model, img):\n",
        "    with torch.no_grad():#Always turn off gradients when evaluating\n",
        "        w, h = img.shape#Whats the width/height of the image\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            img = torch.tensor(img)\n",
        "        x = img.reshape(1,-1,w,h)#reshape it as (B, C, W, H)\n",
        "        logits = model(x) #Get the logits\n",
        "        y_hat = F.softmax(logits, dim=1)#Turn into probabilities \n",
        "        return y_hat.numpy().flatten()#convert prediction to numpy array. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:02:47.449121Z",
          "start_time": "2021-03-22T15:02:47.432158Z"
        }
      },
      "source": [
        "img_pred = pred(model, img)\n",
        "img_lr_pred = pred(model, img_lr)\n",
        "img_ul_pred = pred(model, img_ul)\n",
        "\n",
        "print(\"Org Img Class {} Prob:         \".format(correct_class) , img_pred[correct_class])\n",
        "print(\"Lower Right Img Class {} Prob: \".format(correct_class) , img_lr_pred[correct_class])\n",
        "print(\"Uper Left Img Class {} Prob:   \".format(correct_class) , img_ul_pred[correct_class])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:09:01.336880Z",
          "start_time": "2021-03-22T15:02:47.468427Z"
        },
        "tags": [
          "remove_output"
        ]
      },
      "source": [
        "model_cnn_pool = nn.Sequential(\n",
        "  nn.Conv2d(C, filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(filters, filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(filters, filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.MaxPool2d(2),\n",
        "  nn.Conv2d(filters, 2*filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.MaxPool2d(2),\n",
        "\n",
        "  nn.Flatten(), \n",
        "  #Why did we reduce the number of units into the Linear layer by a factor of $4^2$? Because pooling a 2x2 grid down to one value means we go from 4 values, down to 1, and we did this two times. \n",
        "  nn.Linear(2*filters*D//(4**2), classes),\n",
        ")\n",
        "\n",
        "cnn_results_with_pool = train_simple_network(model_cnn_pool, loss_func, mnist_train_loader, test_loader=mnist_test_loader, score_funcs={'Accuracy': accuracy_score}, device=device, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:09:01.353894Z",
          "start_time": "2021-03-22T15:09:01.338110Z"
        }
      },
      "source": [
        "model = model_cnn_pool.cpu().eval()\n",
        "img_pred = pred(model, img)\n",
        "img_lr_pred = pred(model, img_lr)\n",
        "img_ul_pred = pred(model, img_ul)\n",
        "\n",
        "print(\"Org Img Class {} Prob:         \".format(correct_class) , img_pred[correct_class])\n",
        "print(\"Lower Right Img Class {} Prob: \".format(correct_class) , img_lr_pred[correct_class])\n",
        "print(\"Uper Left Img Class {} Prob:   \".format(correct_class) , img_ul_pred[correct_class])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:09:01.598559Z",
          "start_time": "2021-03-22T15:09:01.355242Z"
        }
      },
      "source": [
        "sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results, label='Simple CNN')\n",
        "sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results_with_pool, label='CNN w/ Max Pooling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:09:02.472082Z",
          "start_time": "2021-03-22T15:09:01.599867Z"
        }
      },
      "source": [
        "#Several built-in transformations, given some agressive values to make their impact more obvious.  \n",
        "sample_transforms = {\n",
        "    \"Rotation\" : transforms.RandomAffine(degrees=45),\n",
        "    \"Translation\" : transforms.RandomAffine(degrees=0, translate=(0.1,0.1)),\n",
        "    \"Shear\": transforms.RandomAffine(degrees=0, shear=45),\n",
        "    \"RandomCrop\" : transforms.RandomCrop((20,20)),\n",
        "    \"Horizontal Flip\" : transforms.RandomHorizontalFlip(p=1.0),\n",
        "    \"Vertical Flip\": transforms.RandomVerticalFlip(p=1.0),\n",
        "    \"Perspective\": transforms.RandomPerspective(p=1.0),   \n",
        "    \"ColorJitter\" : transforms.ColorJitter(brightness=0.9, contrast=0.9)\n",
        "}\n",
        "#Convert the Tensor image back to a PIL image using a transform\n",
        "pil_img = transforms.ToPILImage()(img)\n",
        "#Plot a randomy application of each transform\n",
        "f, axarr = plt.subplots(2,4)\n",
        "for count, (name, t) in enumerate(sample_transforms.items()):\n",
        "    row = count % 4\n",
        "    col = count // 4\n",
        "    axarr[col,row].imshow(t(pil_img), cmap='gray')\n",
        "    axarr[col,row].set_title(name)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:09:02.499210Z",
          "start_time": "2021-03-22T15:09:02.473350Z"
        }
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.98, 1.02)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.ToTensor()\n",
        "\n",
        "mnist_train_t = torchvision.datasets.MNIST(\"./data\", train=True, transform=train_transform)\n",
        "mnist_test_t = torchvision.datasets.MNIST(\"./data\", train=False, transform=test_transform)\n",
        "mnist_train_loader_t = DataLoader(mnist_train_t, shuffle=True,  batch_size=B, num_workers=5)\n",
        "mnist_test_loader_t = DataLoader(mnist_test_t, batch_size=B, num_workers=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:13:44.875053Z",
          "start_time": "2021-03-22T15:09:02.500926Z"
        },
        "tags": [
          "remove_output"
        ]
      },
      "source": [
        "model_cnn_pool = nn.Sequential(\n",
        "  nn.Conv2d(C, filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(filters, filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(filters, filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.MaxPool2d(2),\n",
        "  nn.Conv2d(filters, 2*filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2), \n",
        "  nn.Tanh(),\n",
        "  nn.MaxPool2d(2),\n",
        "  nn.Flatten(), \n",
        "  nn.Linear(2*filters*D//(4**2), classes),\n",
        ")\n",
        "\n",
        "cnn_results_with_pool_augmented = train_simple_network(model_cnn_pool, loss_func, mnist_train_loader_t, test_loader=mnist_test_loader_t, score_funcs={'Accuracy': accuracy_score}, device=device, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-22T15:13:45.117991Z",
          "start_time": "2021-03-22T15:13:44.876560Z"
        }
      },
      "source": [
        "sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results_with_pool, label='CNN w/ Max Pooling')\n",
        "sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results_with_pool_augmented, label='CNN w/ Max Pooling + Augmentation')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}